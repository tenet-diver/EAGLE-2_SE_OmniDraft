2025-07-08 15:51:20,925 - INFO - <module>:71 - Starting tokenizer loading...
2025-07-08 15:51:20,925 - DEBUG - <module>:76 - Loading tiny tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 15:51:20,957 - DEBUG - _new_conn:939 - Starting new HTTPS connection (1): huggingface.co:443
2025-07-08 15:51:21,076 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 15:51:21,099 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 15:51:21,210 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/special_tokens_map.json HTTP/1.1" 307 0
2025-07-08 15:51:21,338 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json HTTP/1.1" 200 0
2025-07-08 15:51:21,340 - DEBUG - acquire:181 - Attempting to acquire lock 140501148469376 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/492d4b2966a1763442d426d880dbc29f94906e4c.lock
2025-07-08 15:51:21,340 - DEBUG - acquire:184 - Lock 140501148469376 acquired on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/492d4b2966a1763442d426d880dbc29f94906e4c.lock
2025-07-08 15:51:21,493 - DEBUG - _make_request:433 - https://huggingface.co:443 "GET /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/special_tokens_map.json HTTP/1.1" 200 551
2025-07-08 15:51:21,550 - DEBUG - release:216 - Attempting to release lock 140501148469376 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/492d4b2966a1763442d426d880dbc29f94906e4c.lock
2025-07-08 15:51:21,551 - DEBUG - release:219 - Lock 140501148469376 released on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/492d4b2966a1763442d426d880dbc29f94906e4c.lock
2025-07-08 15:51:21,735 - DEBUG - <module>:78 - Tiny tokenizer vocab size: 32000
2025-07-08 15:51:21,735 - DEBUG - <module>:79 - Tiny tokenizer EOS token: 2
2025-07-08 15:51:21,735 - DEBUG - <module>:81 - Loading large tokenizer: Qwen/Qwen3-0.6B
2025-07-08 15:51:21,854 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 15:51:21,993 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 15:51:21,996 - DEBUG - acquire:181 - Attempting to acquire lock 140501148467840 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/417d038a63fa3de29cfde265caedae14d1a58d92.lock
2025-07-08 15:51:21,996 - DEBUG - acquire:184 - Lock 140501148467840 acquired on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/417d038a63fa3de29cfde265caedae14d1a58d92.lock
2025-07-08 15:51:22,136 - DEBUG - _make_request:433 - https://huggingface.co:443 "GET /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 None
2025-07-08 15:51:22,143 - DEBUG - release:216 - Attempting to release lock 140501148467840 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/417d038a63fa3de29cfde265caedae14d1a58d92.lock
2025-07-08 15:51:22,144 - DEBUG - release:219 - Lock 140501148467840 released on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/417d038a63fa3de29cfde265caedae14d1a58d92.lock
2025-07-08 15:51:22,338 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/vocab.json HTTP/1.1" 307 0
2025-07-08 15:51:22,477 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/vocab.json HTTP/1.1" 200 0
2025-07-08 15:51:22,478 - DEBUG - acquire:181 - Attempting to acquire lock 140501183637104 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/4783fe10ac3adce15ac8f358ef5462739852c569.lock
2025-07-08 15:51:22,479 - DEBUG - acquire:184 - Lock 140501183637104 acquired on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/4783fe10ac3adce15ac8f358ef5462739852c569.lock
2025-07-08 15:51:22,613 - DEBUG - _make_request:433 - https://huggingface.co:443 "GET /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/vocab.json HTTP/1.1" 200 None
2025-07-08 15:51:22,926 - DEBUG - release:216 - Attempting to release lock 140501183637104 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/4783fe10ac3adce15ac8f358ef5462739852c569.lock
2025-07-08 15:51:22,927 - DEBUG - release:219 - Lock 140501183637104 released on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/4783fe10ac3adce15ac8f358ef5462739852c569.lock
2025-07-08 15:51:23,042 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/merges.txt HTTP/1.1" 307 0
2025-07-08 15:51:23,213 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/merges.txt HTTP/1.1" 200 0
2025-07-08 15:51:23,214 - DEBUG - acquire:181 - Attempting to acquire lock 140501148821200 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock
2025-07-08 15:51:23,214 - DEBUG - acquire:184 - Lock 140501148821200 acquired on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock
2025-07-08 15:51:23,341 - DEBUG - _make_request:433 - https://huggingface.co:443 "GET /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/merges.txt HTTP/1.1" 200 None
2025-07-08 15:51:23,804 - DEBUG - release:216 - Attempting to release lock 140501148821200 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock
2025-07-08 15:51:23,818 - DEBUG - release:219 - Lock 140501148821200 released on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock
2025-07-08 15:51:23,957 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer.json HTTP/1.1" 302 0
2025-07-08 15:51:23,978 - DEBUG - acquire:181 - Attempting to acquire lock 140501148469376 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/aeb13307a71acd8fe81861d94ad54ab689df773318809eed3cbe794b4492dae4.lock
2025-07-08 15:51:23,979 - DEBUG - acquire:184 - Lock 140501148469376 acquired on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/aeb13307a71acd8fe81861d94ad54ab689df773318809eed3cbe794b4492dae4.lock
2025-07-08 15:51:24,495 - DEBUG - _make_request:433 - https://huggingface.co:443 "GET /api/models/Qwen/Qwen3-0.6B/xet-read-token/e6de91484c29aa9480d55605af694f39b081c455 HTTP/1.1" 200 379
2025-07-08 15:51:26,713 - DEBUG - release:216 - Attempting to release lock 140501148469376 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/aeb13307a71acd8fe81861d94ad54ab689df773318809eed3cbe794b4492dae4.lock
2025-07-08 15:51:26,713 - DEBUG - release:219 - Lock 140501148469376 released on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--Qwen--Qwen3-0.6B/aeb13307a71acd8fe81861d94ad54ab689df773318809eed3cbe794b4492dae4.lock
2025-07-08 15:51:26,822 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/added_tokens.json HTTP/1.1" 404 0
2025-07-08 15:51:26,929 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/special_tokens_map.json HTTP/1.1" 404 0
2025-07-08 15:51:27,579 - DEBUG - <module>:83 - Large tokenizer vocab size: 151643
2025-07-08 15:51:27,579 - DEBUG - <module>:84 - Large tokenizer EOS token: 151645
2025-07-08 15:51:27,580 - INFO - <module>:86 - Tokenizers loaded successfully
2025-07-08 15:51:27,580 - INFO - load_model_efficiently:46 - Starting model load: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 15:51:27,580 - DEBUG - load_model_efficiently:47 - Device: cpu, Offload to CPU: False
2025-07-08 15:51:27,580 - DEBUG - clear_gpu_memory:34 - Clearing GPU memory cache
2025-07-08 15:51:27,580 - DEBUG - clear_gpu_memory:42 - CUDA not available, skipping GPU memory clear
2025-07-08 15:51:27,580 - DEBUG - load_model_efficiently:52 - Loading model with torch.float16 precision
2025-07-08 15:51:27,684 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json HTTP/1.1" 307 0
2025-07-08 15:51:27,840 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 0
2025-07-08 15:51:27,843 - DEBUG - acquire:181 - Attempting to acquire lock 140501183638496 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/4ea05f1bc289d48ba9b92eea2f58ad8acd3dce5d.lock
2025-07-08 15:51:27,843 - DEBUG - acquire:184 - Lock 140501183638496 acquired on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/4ea05f1bc289d48ba9b92eea2f58ad8acd3dce5d.lock
2025-07-08 15:51:27,974 - DEBUG - _make_request:433 - https://huggingface.co:443 "GET /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 608
2025-07-08 15:51:27,979 - DEBUG - release:216 - Attempting to release lock 140501183638496 on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/4ea05f1bc289d48ba9b92eea2f58ad8acd3dce5d.lock
2025-07-08 15:51:27,979 - DEBUG - release:219 - Lock 140501183638496 released on /Users/rustameynaliyev/.cache/huggingface/hub/.locks/models--TinyLlama--TinyLlama-1.1B-Chat-v1.0/4ea05f1bc289d48ba9b92eea2f58ad8acd3dce5d.lock
2025-07-08 15:55:08,775 - INFO - <module>:71 - Starting tokenizer loading...
2025-07-08 15:55:08,776 - DEBUG - <module>:76 - Loading tiny tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 15:55:08,796 - DEBUG - _new_conn:939 - Starting new HTTPS connection (1): huggingface.co:443
2025-07-08 15:55:08,908 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 15:55:08,919 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 15:55:09,073 - DEBUG - <module>:78 - Tiny tokenizer vocab size: 32000
2025-07-08 15:55:09,073 - DEBUG - <module>:79 - Tiny tokenizer EOS token: 2
2025-07-08 15:55:09,073 - DEBUG - <module>:81 - Loading large tokenizer: Qwen/Qwen3-0.6B
2025-07-08 15:55:09,203 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 15:55:09,223 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 15:55:09,903 - DEBUG - <module>:83 - Large tokenizer vocab size: 151643
2025-07-08 15:55:09,903 - DEBUG - <module>:84 - Large tokenizer EOS token: 151645
2025-07-08 15:55:09,903 - INFO - <module>:86 - Tokenizers loaded successfully
2025-07-08 15:55:09,904 - INFO - load_model_efficiently:46 - Starting model load: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 15:55:09,904 - DEBUG - load_model_efficiently:47 - Device: cpu, Offload to CPU: False
2025-07-08 15:55:09,904 - DEBUG - clear_gpu_memory:34 - Clearing GPU memory cache
2025-07-08 15:55:09,904 - DEBUG - clear_gpu_memory:42 - CUDA not available, skipping GPU memory clear
2025-07-08 15:55:09,904 - DEBUG - load_model_efficiently:52 - Loading model with torch.float16 precision
2025-07-08 15:55:10,204 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json HTTP/1.1" 307 0
2025-07-08 15:55:10,229 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 0
2025-07-08 16:04:28,659 - INFO - <module>:71 - Starting tokenizer loading...
2025-07-08 16:04:28,660 - DEBUG - <module>:76 - Loading tiny tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:04:28,701 - DEBUG - _new_conn:939 - Starting new HTTPS connection (1): huggingface.co:443
2025-07-08 16:04:28,837 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:04:28,858 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:04:29,014 - DEBUG - <module>:78 - Tiny tokenizer vocab size: 32000
2025-07-08 16:04:29,014 - DEBUG - <module>:79 - Tiny tokenizer EOS token: 2
2025-07-08 16:04:29,014 - DEBUG - <module>:81 - Loading large tokenizer: Qwen/Qwen3-0.6B
2025-07-08 16:04:29,124 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:04:29,144 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:04:29,789 - DEBUG - <module>:83 - Large tokenizer vocab size: 151643
2025-07-08 16:04:29,789 - DEBUG - <module>:84 - Large tokenizer EOS token: 151645
2025-07-08 16:04:29,789 - INFO - <module>:86 - Tokenizers loaded successfully
2025-07-08 16:04:29,789 - INFO - load_model_efficiently:46 - Starting model load: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:04:29,789 - DEBUG - load_model_efficiently:47 - Device: cpu, Offload to CPU: False
2025-07-08 16:04:29,789 - DEBUG - clear_gpu_memory:34 - Clearing GPU memory cache
2025-07-08 16:04:29,789 - DEBUG - clear_gpu_memory:42 - CUDA not available, skipping GPU memory clear
2025-07-08 16:04:29,789 - DEBUG - load_model_efficiently:52 - Loading model with torch.float16 precision
2025-07-08 16:04:29,902 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json HTTP/1.1" 307 0
2025-07-08 16:04:29,920 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 0
2025-07-08 16:04:52,878 - INFO - <module>:71 - Starting tokenizer loading...
2025-07-08 16:04:52,879 - DEBUG - <module>:76 - Loading tiny tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:04:52,894 - DEBUG - _new_conn:939 - Starting new HTTPS connection (1): huggingface.co:443
2025-07-08 16:04:53,030 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:04:53,061 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:04:53,314 - DEBUG - <module>:78 - Tiny tokenizer vocab size: 32000
2025-07-08 16:04:53,314 - DEBUG - <module>:79 - Tiny tokenizer EOS token: 2
2025-07-08 16:04:53,315 - DEBUG - <module>:81 - Loading large tokenizer: Qwen/Qwen3-0.6B
2025-07-08 16:04:53,453 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:04:53,469 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:04:54,093 - DEBUG - <module>:83 - Large tokenizer vocab size: 151643
2025-07-08 16:04:54,093 - DEBUG - <module>:84 - Large tokenizer EOS token: 151645
2025-07-08 16:04:54,093 - INFO - <module>:86 - Tokenizers loaded successfully
2025-07-08 16:04:54,093 - INFO - load_model_efficiently:46 - Starting model load: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:04:54,093 - DEBUG - load_model_efficiently:47 - Device: cpu, Offload to CPU: False
2025-07-08 16:04:54,093 - DEBUG - clear_gpu_memory:34 - Clearing GPU memory cache
2025-07-08 16:04:54,093 - DEBUG - clear_gpu_memory:42 - CUDA not available, skipping GPU memory clear
2025-07-08 16:04:54,093 - DEBUG - load_model_efficiently:52 - Loading model with torch.float16 precision
2025-07-08 16:04:54,208 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json HTTP/1.1" 307 0
2025-07-08 16:04:54,223 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 0
2025-07-08 16:07:43,157 - INFO - <module>:71 - Starting tokenizer loading...
2025-07-08 16:07:43,158 - DEBUG - <module>:76 - Loading tiny tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:07:43,200 - DEBUG - _new_conn:939 - Starting new HTTPS connection (1): huggingface.co:443
2025-07-08 16:07:43,418 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:07:43,488 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:07:43,653 - DEBUG - <module>:78 - Tiny tokenizer vocab size: 32000
2025-07-08 16:07:43,653 - DEBUG - <module>:79 - Tiny tokenizer EOS token: 2
2025-07-08 16:07:43,653 - DEBUG - <module>:81 - Loading large tokenizer: Qwen/Qwen3-0.6B
2025-07-08 16:07:43,781 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:07:43,846 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:07:44,491 - DEBUG - <module>:83 - Large tokenizer vocab size: 151643
2025-07-08 16:07:44,491 - DEBUG - <module>:84 - Large tokenizer EOS token: 151645
2025-07-08 16:07:44,491 - INFO - <module>:86 - Tokenizers loaded successfully
2025-07-08 16:07:44,491 - INFO - load_model_efficiently:46 - Starting model load: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:07:44,491 - DEBUG - load_model_efficiently:47 - Device: cpu, Offload to CPU: False
2025-07-08 16:07:44,491 - DEBUG - clear_gpu_memory:34 - Clearing GPU memory cache
2025-07-08 16:07:44,491 - DEBUG - clear_gpu_memory:42 - CUDA not available, skipping GPU memory clear
2025-07-08 16:07:44,492 - DEBUG - load_model_efficiently:52 - Loading model with torch.float16 precision
2025-07-08 16:07:44,620 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json HTTP/1.1" 307 0
2025-07-08 16:07:44,681 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 0
2025-07-08 16:14:13,255 - INFO - <module>:71 - Starting tokenizer loading...
2025-07-08 16:14:13,255 - DEBUG - <module>:76 - Loading tiny tokenizer: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:14:13,273 - DEBUG - _new_conn:939 - Starting new HTTPS connection (1): huggingface.co:443
2025-07-08 16:14:13,418 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:14:13,435 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:14:13,605 - DEBUG - <module>:78 - Tiny tokenizer vocab size: 32000
2025-07-08 16:14:13,606 - DEBUG - <module>:79 - Tiny tokenizer EOS token: 2
2025-07-08 16:14:13,606 - DEBUG - <module>:81 - Loading large tokenizer: Qwen/Qwen3-0.6B
2025-07-08 16:14:13,715 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-07-08 16:14:13,731 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/e6de91484c29aa9480d55605af694f39b081c455/tokenizer_config.json HTTP/1.1" 200 0
2025-07-08 16:14:14,411 - DEBUG - <module>:83 - Large tokenizer vocab size: 151643
2025-07-08 16:14:14,412 - DEBUG - <module>:84 - Large tokenizer EOS token: 151645
2025-07-08 16:14:14,412 - INFO - <module>:86 - Tokenizers loaded successfully
2025-07-08 16:14:14,412 - INFO - load_model_efficiently:46 - Starting model load: TinyLlama/TinyLlama-1.1B-Chat-v1.0
2025-07-08 16:14:14,412 - DEBUG - load_model_efficiently:47 - Device: cpu, Offload to CPU: False
2025-07-08 16:14:14,412 - DEBUG - clear_gpu_memory:34 - Clearing GPU memory cache
2025-07-08 16:14:14,412 - DEBUG - clear_gpu_memory:42 - CUDA not available, skipping GPU memory clear
2025-07-08 16:14:14,412 - DEBUG - load_model_efficiently:52 - Loading model with torch.float16 precision
2025-07-08 16:14:14,518 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /TinyLlama/TinyLlama-1.1B-Chat-v1.0/resolve/main/config.json HTTP/1.1" 307 0
2025-07-08 16:14:14,533 - DEBUG - _make_request:433 - https://huggingface.co:443 "HEAD /api/resolve-cache/models/TinyLlama/TinyLlama-1.1B-Chat-v1.0/fe8a4ea1ffedaf415f4da2f062534de366a451e6/config.json HTTP/1.1" 200 0
